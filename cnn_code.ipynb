{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference:  https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/06_CIFAR-10.ipynb\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "# Various constants for the size of the images.\n",
    "# Width and height of each image.\n",
    "img_size = 32\n",
    "# Number of channels in each image\n",
    "num_channels = 3\n",
    "# Length of an image when flattened to a 1-dim array.\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "# Number of classes.\n",
    "num_classes = 10\n",
    "# Various constants used to allocate arrays of the correct size.\n",
    "# Number of files for the training-set.\n",
    "_num_files_train = 5\n",
    "# Number of images for each batch-file in the training-set.\n",
    "_images_per_file = 10000\n",
    "# Total number of images in the training-set.\n",
    "# This is used to pre-allocate arrays for efficiency.\n",
    "_num_images_train = _num_files_train * _images_per_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting data\n",
    "# Assuming t\n",
    "data_path='data/CIFAR-10'\n",
    "tar_path='data/CIFAR-10/cifar-10-python.tar.gz'\n",
    "with tarfile.open(tar_path) as tar:\n",
    "    tar.extractall(path=data_path)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Return the full path of a data-file for the data-set\n",
    "def _get_file_path(filename=\"\"):\n",
    "    return os.path.join(data_path, \"cifar-10-batches-py/\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the names for the classes in the CIFAR-10 data-set. Returns a list with the names. \n",
    "def _unpickle(filename):\n",
    "    file_path = _get_file_path(filename)\n",
    "    with open(file_path, mode='rb') as file:\n",
    "        data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the names for the classes in the CIFAR-10 data-set. Returns a list with the names. \n",
    "def load_class_names():\n",
    "    # Load the class-names from the pickled file.\n",
    "    raw = _unpickle(filename=\"batches.meta\")[b'label_names']\n",
    "    # Convert from binary strings.\n",
    "    names = [x.decode('utf-8') for x in raw]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert images from the CIFAR-10 format and return a 4-dim array with shape: [image_number, height, width, channel]\n",
    "def _convert_images(raw):\n",
    "    # Convert the raw images from the data-files to floating-points.\n",
    "    raw_float = np.array(raw, dtype=float) / 255.0\n",
    "    # Reshape the array to 4-dimensions.\n",
    "    images = raw_float.reshape([-1, num_channels, img_size, img_size])\n",
    "    # Reorder the indices of the array.\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a pickled data-file from the CIFAR-10 data-set and return the converted images (see above) and the class-number for each image.\n",
    "def _load_data(filename):\n",
    "    # Load the pickled data-file.\n",
    "    data = _unpickle(filename)\n",
    "    # Get the raw images.\n",
    "    raw_images = data[b'data']\n",
    "    # Get the class-numbers for each image. Convert to numpy-array.\n",
    "    cls = np.array(data[b'labels'])\n",
    "    # Convert the images.\n",
    "    images = _convert_images(raw_images)\n",
    "    return images, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the training-data for the CIFAR-10 data-set. The data-set is split into 5 data-files which are merged here.\n",
    "# Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "def load_training_data():\n",
    "    # Pre-allocate the arrays for the images and class-numbers for efficiency.\n",
    "    images = np.zeros(shape=[_num_images_train, img_size, img_size, num_channels], dtype=float)\n",
    "    cls = np.zeros(shape=[_num_images_train], dtype=int)\n",
    "    # Begin-index for the current batch.\n",
    "    begin = 0\n",
    "    # For each data-file.\n",
    "    for i in range(_num_files_train):\n",
    "        # Load the images and class-numbers from the data-file.\n",
    "        images_batch, cls_batch = _load_data(filename=\"data_batch_\" + str(i + 1))\n",
    "        # Number of images in this batch.\n",
    "        num_images = len(images_batch)\n",
    "        # End-index for the current batch.\n",
    "        end = begin + num_images\n",
    "        # Store the images into the array.\n",
    "        images[begin:end, :] = images_batch\n",
    "        # Store the class-numbers into the array.\n",
    "        cls[begin:end] = cls_batch\n",
    "        # The begin-index for the next batch is the current end-index.\n",
    "        begin = end\n",
    "    return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all the test-data for the CIFAR-10 data-set. Returns the images, class-numbers and one-hot encoded class-labels.\n",
    "def load_test_data():\n",
    "    images, cls = _load_data(filename=\"test_batch\")\n",
    "    return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate the One-Hot encoded class-labels from an array of integers.\n",
    "def one_hot_encoded(class_numbers, num_classes=None):\n",
    "    # Find the number of classes if None is provided.\n",
    "    # Assumes the lowest class-number is zero.\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(class_numbers) + 1\n",
    "    return np.eye(num_classes, dtype=float)[class_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = load_class_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, cls_train, labels_train = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, cls_test, labels_test = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "# placeholder variable for true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "#placeholder variable for the class-number\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_cropped = 24\n",
    "#This function takes a single image as input, and a boolean whether to build the training or testing graph.\n",
    "def pre_process_image(image, training):\n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For testing, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,target_height=img_size_cropped,target_width=img_size_cropped)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Use TensorFlow to loop over all the input images and call the function above which takes a single image as input.\n",
    "def pre_process(images, training):\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the network architecture\n",
    "def main_network(images, training):\n",
    "    # Wrap the input images as a Pretty Tensor object.\n",
    "    x_pretty = pt.wrap(images)\n",
    "    # Pretty Tensor uses special numbers to distinguish between the training and testing phases.\n",
    "    if training:\n",
    "        phase = pt.Phase.train\n",
    "    else:\n",
    "        phase = pt.Phase.infer\n",
    "    # Create the convolutional neural network of the recommended architecture\n",
    "    with pt.defaults_scope(activation_fn=tf.nn.relu, phase=phase):\n",
    "        y_pred, loss = x_pretty.\\\n",
    "            conv2d(kernel=5, depth=64, name='layer_conv1', batch_normalize=True).\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            conv2d(kernel=5, depth=64, name='layer_conv2').\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            flatten().\\\n",
    "            fully_connected(size=256, name='layer_fc1').\\\n",
    "            fully_connected(size=128, name='layer_fc2').\\\n",
    "            softmax_classifier(num_classes=num_classes, labels=y_true)\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network(training):\n",
    "    # Wrap the neural network in the scope named 'network'.\n",
    "    # Create new variables during training, and re-use during testing.\n",
    "    with tf.variable_scope('network', reuse=not training):\n",
    "        # Just rename the input placeholder variable for convenience.\n",
    "        images = x\n",
    "        # Create TensorFlow graph for pre-processing.\n",
    "        images = pre_process(images=images, training=training)\n",
    "        # Create TensorFlow graph for the main processing.\n",
    "        y_pred, loss = main_network(images=images, training=training)\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keeps track of iteration number\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, loss = create_network(training=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predicted vector from network\n",
    "y_pred, _ = create_network(training=False)\n",
    "#Get predicted class from the vector\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "#Get vector of booleans representing if predicted class is equal to actual class\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "#Get classification accurscy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save variales of graph\n",
    "saver = tf.train.Saver()\n",
    "session = tf.Session()\n",
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'cifar10_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "Failed to restore checkpoint. Initializing variables instead.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Use TensorFlow to find the latest checkpoint - if any.\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "    # Try and load the data in the checkpoint.\n",
    "    saver.restore(session, save_path=last_chk_path)\n",
    "    # If we get to this point, the checkpoint was successfully loaded.\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    # If the above failed for some reason, simply initialize all the variables for the TensorFlow graph.\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Minibatch training\n",
    "train_batch_size = 64\n",
    "def random_batch():\n",
    "    # Number of images in the training-set.\n",
    "    num_images = len(images_train)\n",
    "\n",
    "    # Create a random index.\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "\n",
    "    # Use the random index to select random images and labels.\n",
    "    x_batch = images_train[idx, :, :, :]\n",
    "    y_batch = labels_train[idx, :]\n",
    "\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To store test & training batch accuracy after model has been trained for every 100 iterations\n",
    "global_arr=[]\n",
    "batch_acc_arr=[]\n",
    "test_acc_arr=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the network\n",
    "def optimize(num_iterations):\n",
    "    # Start-time used for printing time-usage below.    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples. x_batch now holds a batch of images and y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "        # Put the batch into a dict with the proper names for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        # Run the optimizer using this batch of training data. TensorFlow assigns the variables in feed_dict_train to the placeholder variables and then runs the optimizer.\n",
    "        # We also want to retrieve the global_step counter.\n",
    "        i_global, _ = session.run([global_step, optimizer], feed_dict=feed_dict_train)\n",
    "\n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            batch_acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "            global_arr.append(i_global)\n",
    "            batch_acc_arr.append(batch_acc)\n",
    "            test_acc_arr.append(print_test_accuracy())\n",
    "\n",
    "        # Save a checkpoint to disk every 1000 iterations (and last).\n",
    "        if (i_global % 1000 == 0) or (i == num_iterations - 1):\n",
    "            # Save all variables of the TensorFlow graph to a checkpoint. Append the global_step counter to the filename so we save the last several checkpoints.\n",
    "            saver.save(session, save_path=save_path, global_step=global_step)         \n",
    "            print(\"Saved checkpoint.\")\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data-set in batches of this size to limit RAM usage.\n",
    "batch_size = 256\n",
    "# Calculates the predicted classes of images and also returns a boolean array whether the classification of each image is correct\n",
    "def predict_cls(images, labels, cls_true):\n",
    "    # Number of images.\n",
    "    num_images = len(images)\n",
    "\n",
    "    # Allocate an array for the predicted classes which will be calculated in batches and filled into this array.\n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches. We will just iterate through all the batches. There might be a more clever and Pythonic way of doing this.\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "    while i < num_images:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + batch_size, num_images)\n",
    "        # Create a feed-dict with the images and labels  between index i and j.\n",
    "        feed_dict = {x: images[i:j, :], y_true: labels[i:j, :]}\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        # Set the start-index for the next batch to the end-index of the current batch.\n",
    "        i = j\n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = (cls_true == cls_pred)\n",
    "    return correct, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate the predicted class for the test-set.\n",
    "def predict_cls_test():\n",
    "    return predict_cls(images = images_test, labels = labels_test, cls_true = cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Printing the classification accuracy on the test-set\n",
    "def print_test_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "    # For all the images in the test-set,\n",
    "    # calculate the predicted classes and whether they are correct.\n",
    "    correct, cls_pred = predict_cls_test()\n",
    "    \n",
    "    # Classification accuracy and the number of correct classifications.\n",
    "    acc, num_correct = classification_accuracy(correct)\n",
    "    \n",
    "    # Number of images being classified.\n",
    "    num_images = len(correct)\n",
    "\n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, num_correct, num_images))\n",
    "\n",
    "    # Plot some examples of mis-classifications, if desired.\n",
    "    if show_example_errors:\n",
    "        print(\"Example errors:\")\n",
    "        plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "    # Plot the confusion matrix, if desired.\n",
    "    if show_confusion_matrix:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        plot_confusion_matrix(cls_pred=cls_pred)\n",
    "        \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculates the classification accuracy \n",
    "def classification_accuracy(correct):\n",
    "    # Return the classification accuracy and the number of correct classifications.\n",
    "    return correct.mean(), correct.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:    100, Training Batch Accuracy:  32.8%\n",
      "Global Step:    200, Training Batch Accuracy:  32.8%\n",
      "Global Step:    300, Training Batch Accuracy:  37.5%\n",
      "Global Step:    400, Training Batch Accuracy:  48.4%\n",
      "Global Step:    500, Training Batch Accuracy:  48.4%\n",
      "Global Step:    600, Training Batch Accuracy:  46.9%\n",
      "Global Step:    700, Training Batch Accuracy:  34.4%\n",
      "Global Step:    800, Training Batch Accuracy:  48.4%\n",
      "Global Step:    900, Training Batch Accuracy:  43.8%\n",
      "Global Step:   1000, Training Batch Accuracy:  39.1%\n",
      "Saved checkpoint.\n",
      "Global Step:   1100, Training Batch Accuracy:  37.5%\n",
      "Global Step:   1200, Training Batch Accuracy:  42.2%\n",
      "Global Step:   1300, Training Batch Accuracy:  53.1%\n",
      "Global Step:   1400, Training Batch Accuracy:  37.5%\n",
      "Global Step:   1500, Training Batch Accuracy:  46.9%\n",
      "Global Step:   1600, Training Batch Accuracy:  43.8%\n",
      "Global Step:   1700, Training Batch Accuracy:  39.1%\n",
      "Global Step:   1800, Training Batch Accuracy:  56.2%\n",
      "Global Step:   1900, Training Batch Accuracy:  50.0%\n",
      "Global Step:   2000, Training Batch Accuracy:  54.7%\n",
      "Saved checkpoint.\n",
      "Global Step:   2100, Training Batch Accuracy:  43.8%\n",
      "Global Step:   2200, Training Batch Accuracy:  50.0%\n",
      "Global Step:   2300, Training Batch Accuracy:  48.4%\n",
      "Global Step:   2400, Training Batch Accuracy:  45.3%\n",
      "Global Step:   2500, Training Batch Accuracy:  59.4%\n",
      "Global Step:   2600, Training Batch Accuracy:  45.3%\n",
      "Global Step:   2700, Training Batch Accuracy:  57.8%\n",
      "Global Step:   2800, Training Batch Accuracy:  54.7%\n",
      "Global Step:   2900, Training Batch Accuracy:  46.9%\n",
      "Global Step:   3000, Training Batch Accuracy:  48.4%\n",
      "Saved checkpoint.\n",
      "Global Step:   3100, Training Batch Accuracy:  37.5%\n",
      "Global Step:   3200, Training Batch Accuracy:  57.8%\n",
      "Global Step:   3300, Training Batch Accuracy:  51.6%\n",
      "Global Step:   3400, Training Batch Accuracy:  59.4%\n",
      "Global Step:   3500, Training Batch Accuracy:  50.0%\n",
      "Global Step:   3600, Training Batch Accuracy:  37.5%\n",
      "Global Step:   3700, Training Batch Accuracy:  62.5%\n",
      "Global Step:   3800, Training Batch Accuracy:  56.2%\n",
      "Global Step:   3900, Training Batch Accuracy:  64.1%\n",
      "Global Step:   4000, Training Batch Accuracy:  62.5%\n",
      "Saved checkpoint.\n",
      "Time usage: 0:52:22\n"
     ]
    }
   ],
   "source": [
    "#Start training\n",
    "optimize(num_iterations=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 55.5% (5550 / 10000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55500000000000005"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get final accuracy on test dataset\n",
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot training accuracy vs iterations \n",
    "plt.plot(global_arr, batch_acc_arr, 'r-', label=\"Training Batch Accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#Plot tests accuracy vs iterations\n",
    "plt.plot(global_arr, test_acc_arr, 'b-', label=\"Test Dataset Accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
